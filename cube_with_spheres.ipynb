{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Numpy is used for data manipulation, primarily for vectors and matrices. FAISS is a fast vector search package from Meta that allows for the rapid searching of nearby points in R^3 space. The Ellipsoid class is covered in Ellipsoid.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss_cpu in ./.venv/lib/python3.12/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./.venv/lib/python3.12/site-packages (from faiss_cpu) (2.2.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from faiss_cpu) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss_cpu\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import faiss\n",
    "from ellipsoid import Ellipsoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1000  # Length\n",
    "R_OM = 30.0  # Outer radius mean\n",
    "R_OS = 5.0  # Outer radius standard deviation\n",
    "R_IM = 20.0  # Inner radius mean\n",
    "R_IS = 3.0  # Inner radius standard deviatoin\n",
    "VOL_FR = 0.1  # Volume Fraction, dimensions L^(-3)\n",
    "D1 = 0.1  # Density of core, in points per unit volume\n",
    "D2 = 0.05  # Density of shell, in points per unit volume.\n",
    "TS_M = R_OM - R_IM  # shell thickness mean\n",
    "TS_S = np.sqrt(R_OS**2 - R_IS**2)  # quadrature standard deviation of shell thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Log-normal_distribution\n",
    "# Generate each radius to be used for the spheres\n",
    "sigma_ts = np.sqrt(np.log(1 + (TS_S / TS_M) ** 2)) # thickness standard distribution \n",
    "mu_ts = np.log(TS_M) - sigma_ts**2 / 2 # mean thickness\n",
    "sigma_i = np.sqrt(np.log(1 + (R_IS / R_IM) ** 2)) # Inner radii standard distribution\n",
    "mu_i = np.log(R_IM) - sigma_i**2 / 2 # mean inner radii size\n",
    "R_outer = []\n",
    "R_inner = []\n",
    "sum_vol = 0\n",
    "tgt = (L**3) * VOL_FR\n",
    "while sum_vol < tgt:\n",
    "    thickness = np.random.lognormal(mu_ts, sigma_ts)\n",
    "    ri = np.random.lognormal(mu_i, sigma_i)\n",
    "    ro = thickness + ri\n",
    "    vol = (4 / 3) * np.pi * ((ro**3))\n",
    "    if sum_vol + vol > tgt: # the target cannot be achieved by going over it\n",
    "        break\n",
    "    sum_vol += vol\n",
    "    R_outer.append(ro)\n",
    "    R_inner.append(ri)\n",
    "R_outer = np.array(R_outer)\n",
    "R_inner = np.array(R_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the centers of each spheres\n",
    "\n",
    "Because the spheres should not overlap, each one should be a diameter $d = 2 * r$ away. For simplicity, we allow $r = max\\left(R_{outer}\\right)$.\\\n",
    "[FAISS](https://github.com/facebookresearch/faiss) is a powerful tool for nearest neighbor searches, and allows us to check the minimum distance. In this case, we use `IndexIVFFlat` and a training model in order to allow for fast searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 808\n"
     ]
    }
   ],
   "source": [
    "N = R_outer.shape[0] # the number of spheres\n",
    "print(\"N =\", N)\n",
    "max_r = np.max(R_outer)\n",
    "\n",
    "# PERF: Efficient but approximate, IndexFlatL2 is exact but takes a large amount of time.\n",
    "def gen_points_faiss(\n",
    "    n_pts: int, min_val: float, max_val: float, dist: float, n_batch: int = 100\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate points with minimum distance using Faiss and batching.\n",
    "\n",
    "    Params:\n",
    "    n_pts -- number of points\n",
    "    min_val -- the minmum value on the interval\n",
    "    max_al -- the maximum value on the interval\n",
    "    dist -- the minimum distance between each R^3 point\n",
    "    n_batch -- the number of points to generate per batch\n",
    "    \"\"\"\n",
    "    dim = 3\n",
    "    nlist = 400  # Clusters\n",
    "    quantizer = faiss.IndexFlatL2(dim)\n",
    "    index = faiss.IndexIVFFlat(quantizer, dim, nlist)\n",
    "    training_data = np.random.uniform(\n",
    "        min_val, max_val, size=(int(2000 * np.sqrt(N)), 3)\n",
    "    ).astype(\"float32\")\n",
    "    index.train(training_data)\n",
    "\n",
    "    # index = faiss.IndexHNSWFlat(dim, 20)\n",
    "\n",
    "    pts = []\n",
    "    i = 0\n",
    "\n",
    "    while i < n_pts:\n",
    "        remaining = n_pts - i\n",
    "        current_batch_size = min(n_batch, remaining)\n",
    "\n",
    "        # Generate a batch of candidate points\n",
    "        batch = np.random.uniform(\n",
    "            min_val, max_val, size=(current_batch_size, dim)\n",
    "        ).astype(\"float32\")\n",
    "\n",
    "        if i > 0:\n",
    "            # Neighboring points\n",
    "            D, _ = index.search(batch, 1)\n",
    "            valid = np.sqrt(D[:, 0]) >= dist  # Check distances\n",
    "            valid_points = batch[valid]\n",
    "        else:\n",
    "            valid_points = batch\n",
    "\n",
    "        index.add(valid_points)\n",
    "        pts.extend(valid_points)\n",
    "        i += valid_points.shape[0]\n",
    "\n",
    "    return np.array(pts[:n_pts])\n",
    "# Each point must be within [-L/2 + max(R), L/2 - max(R)]^3\n",
    "centers = gen_points_faiss(N, -L / 2 + max_r, L / 2 - max_r, 2 * max_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the spheres\n",
    "Because we already have a class defined for generating a uniform point distribution in a sphere, we can simply use it again here.\n",
    "In this case, the box surrounding each center should be of length $R_{inner}$ and $R_{outer}$ for the core and shell respectively. Then, we simply shift the generated sphere (which is centered at the origin) by the corresponding `centers[i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_pts = []\n",
    "shell_pts = []\n",
    "for i in range(N):\n",
    "    core = Ellipsoid(D1, R_inner[i])\n",
    "    # shift the points\n",
    "    c = core.make_obj() + centers[i]\n",
    "    for p in c:\n",
    "        core_pts.append(p)\n",
    "    shell = Ellipsoid(D2, R_outer[i], R_inner[i])\n",
    "    s = shell.make_obj() + centers[i]\n",
    "    for p in s:\n",
    "        shell_pts.append(p)\n",
    "core_pts = np.array(core_pts)\n",
    "shell_pts = np.array(shell_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the outputs to specific files\n",
    "\n",
    "We now save the core and shell points to separate files, while also having a large dump file for use with [OVITO](https://www.ovito.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to out.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m append \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaiss\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m save_coords(core_pts)\n\u001b[0;32m---> 27\u001b[0m \u001b[43msave_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshell_pts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout/shell_out_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mappend\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m save_dump([core_pts, shell_pts], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout/all_out_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mappend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dump\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[50], line 23\u001b[0m, in \u001b[0;36msave_coords\u001b[0;34m(points, filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mSave coordinates to a file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m Path(filename)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%.6f\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved to\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename)\n",
      "File \u001b[0;32m~/crease/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1630\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1630\u001b[0m         v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m newline\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1632\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between array dtype (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1633\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat specifier (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1634\u001b[0m                         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mstr\u001b[39m(X\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;28mformat\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def save_dump(points, filename=\"out.dump\", box_len=1000):\n",
    "    \"\"\"\n",
    "    Save coordinates to a dump file, for use with OVITO\n",
    "    \"\"\"\n",
    "    num = sum(pt.shape[0] for pt in points)\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"ITEM: TIMESTEP\\n0\\n\")\n",
    "        f.write(f\"ITEM: NUMBER OF ATOMS\\n{num}\\n\")\n",
    "        f.write(\n",
    "            f\"ITEM: BOX BOUNDS pp pp pp\\n{-box_len // 2} {box_len // 2}\\n{-box_len // 2} {box_len // 2}\\n{-box_len//2} {box_len//2}\\n\"\n",
    "        )\n",
    "        f.write(\"ITEM: ATOMS id type x y z\\n\")\n",
    "        for i in range(0, len(points)):\n",
    "            for j, (x, y, z) in enumerate(points[i], start=1):\n",
    "                f.write(f\"{j} {i + 1} {x:.6f} {y:.6f} {z:.6f}\\n\")\n",
    "        print(\"dumped to\", filename)\n",
    "def save_coords(points, filename=\"out.txt\"):\n",
    "    \"\"\"\n",
    "    Save coordinates to a file\n",
    "    \"\"\"\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savetxt(filename, points, fmt=\"%.6f\")\n",
    "    print(\"saved to\", filename)\n",
    "append = \"faiss\"\n",
    "save_coords(core_pts, f\"out/core_out_{append}.txt\")\n",
    "save_coords(shell_pts, f\"out/shell_out_{append}.txt\")\n",
    "save_dump([core_pts, shell_pts], f\"out/all_out_{append}.dump\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
